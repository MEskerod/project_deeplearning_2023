{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to the zipped folder in your Google Drive\n",
        "tar_file_path = 'RNAStralign.tar.gz' #Change!\n",
        "\n",
        "# Define the folder where you want to unzip the files (in-memory)\n",
        "extracted_folder = 'sequences' #Change name?!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02nqhX6rTML3"
      },
      "source": [
        "# Import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Xm9QjqS8SuKl",
        "outputId": "89c770e5-36d7-4e11-d5b8-52d1c6e1cac8"
      },
      "outputs": [],
      "source": [
        "import tarfile, os\n",
        "\n",
        "# Create the destination folder (in-memory)\n",
        "os.makedirs(extracted_folder, exist_ok=True)\n",
        "\n",
        "# Extract the tar.gz archive\n",
        "with tarfile.open(tar_file_path, 'r:gz') as tar:\n",
        "    tar.extractall(extracted_folder)\n",
        "\n",
        "# List the files in the extracted folder\n",
        "os.listdir(extracted_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from fnmatch import fnmatch\n",
        "\n",
        "root = extracted_folder\n",
        "pattern = \"*.ct\"\n",
        "\n",
        "ct_files = []\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    for name in files:\n",
        "        if fnmatch(name, pattern):\n",
        "            ct_files.append(os.path.join(path, name))\n",
        "with open(\"ct_files.txt\", \"w\") as output:\n",
        "    output.write(\"\\n\".join(ct_files))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Picking files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random as rd\n",
        "\n",
        "def singleFamily(family: str, txt_file=\"ct_files.txt\") -> list:\n",
        "    '''\n",
        "    Returns list of files from a single specified family\n",
        "    '''\n",
        "    ct_files = []\n",
        "    with open(txt_file, \"r\") as file:\n",
        "        for line in file:\n",
        "            if not line.startswith(\"#\") and family in line:\n",
        "                ct_files.append(line.strip())\n",
        "    return ct_files\n",
        "\n",
        "def leaveOneFamilyOut(family: str, txt_file=\"ct_files.txt\"):\n",
        "    '''\n",
        "    Returns list of files from all families except the specified family\n",
        "    '''\n",
        "    ct_files = [] \n",
        "    with open(txt_file, \"r\") as file: \n",
        "        for line in file:\n",
        "            if not line.startswith(\"#\") and family not in line:\n",
        "                ct_files.append(line.strip())\n",
        "    return ct_files\n",
        "\n",
        "def pickFromFamilies(data_size, txt_file=\"ct_files.txt\"):\n",
        "    '''\n",
        "    Returns a list of files with data_size from EACH family.\n",
        "    If a family does not have enough data, all data from that family is added.\n",
        "    '''\n",
        "    ct_files = []\n",
        "    with open(txt_file, \"r\") as file: #Read paths to ct_files\n",
        "        for line in file:\n",
        "            if not line.startswith(\"#\"):\n",
        "                ct_files.append(line.strip())\n",
        "    \n",
        "    families = []\n",
        "    for file in ct_files: #Find all family names\n",
        "        families.append(file.split(\"\\\\\")[2])\n",
        "    families = list(set(families)) #Remove duplicates\n",
        "\n",
        "    data = [] #Create list of lists, where each list contains all files from a family\n",
        "    for family in families:\n",
        "        data.append([line for line in ct_files if family in line])\n",
        "\n",
        "    ct_files = [] \n",
        "    for family in data: #Pick data_size files from each family\n",
        "        try:\n",
        "            ct_files.append(rd.sample(family, data_size))\n",
        "        except:\n",
        "            print(\"Not enough data in family: \", family[0].split(\"\\\\\")[2], \" for size: \", data_size, \".\\n Missing\", data_size-len(family),\"files.\",\"\\n Adding all data from family.\")\n",
        "\n",
        "    return ct_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q-pDdH8TR6A"
      },
      "source": [
        "# Set up preprocessing of RNA files   \n",
        "\n",
        "Below are the functions that is needed for processing the files from .ct files to images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbzpl9-kUwJW"
      },
      "outputs": [],
      "source": [
        "### THESE NEEDS TO BE CHANGED TO FIT WITH LOADING FILES IN COLAB ###\n",
        "\n",
        "def read_bpseq(file: str) -> tuple():\n",
        "    \"\"\"\n",
        "    Takes a .bpseq file and returns the sequence as a string and a list of base pairs\n",
        "    \"\"\"\n",
        "\n",
        "    sequence = \"\"\n",
        "    pairs = []\n",
        "\n",
        "    with open(file, 'r') as f:\n",
        "        lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "    #Remove header - if any\n",
        "    header_lines = 0\n",
        "    for line in lines:\n",
        "        if line[0] == '1':\n",
        "                break\n",
        "        else:\n",
        "            header_lines += 1\n",
        "\n",
        "    lines = lines[header_lines:]\n",
        "\n",
        "    #Make sequence in bp list\n",
        "    for line in lines:\n",
        "        sequence += line[1]\n",
        "        if line[2] != '0':\n",
        "            pairs.append((int(line[0])-1, int(line[2])-1)) #The files start indexing from 1\n",
        "    return sequence, pairs\n",
        "\n",
        "def read_ct(file: str) -> tuple():\n",
        "    \"\"\"\n",
        "    Takes a .ct file and returns the sequence as a string and a list of base pairs\n",
        "    \"\"\"\n",
        "    sequence = \"\"\n",
        "    pairs = []\n",
        "\n",
        "    with open(file, 'r') as f:\n",
        "        lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "    #Remove header - if any\n",
        "    header_lines = 0\n",
        "    for line in lines:\n",
        "        if line[0] == '1':\n",
        "                break\n",
        "        else:\n",
        "            header_lines += 1\n",
        "\n",
        "    lines = lines[header_lines:]\n",
        "\n",
        "    for line in lines:\n",
        "        sequence += line[1]\n",
        "        if line[4] != '0':\n",
        "            pairs.append((int(line[0])-1, int(line[4])-1)) #The files start indexing from 1\n",
        "\n",
        "    return sequence, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTUBnJcQTVxX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_matrix_from_sequence(sequence: str) -> np.array:\n",
        "    \"\"\"\n",
        "    A sequence is converted to a matrix containing all the possible base pairs\n",
        "\n",
        "    If the bases does not form  valid pair the cell is white.\n",
        "    The valid base pairs has the following colors:\n",
        "    GC = green\n",
        "    CG = dark green\n",
        "    UG = blue\n",
        "    GU = dark blue\n",
        "    UA = red\n",
        "    AU = dark red\n",
        "    \"\"\"\n",
        "    colors = {\"invalid_pairing\": [255, 255, 255],\n",
        "              \"unpaired\": [64, 64, 64],\n",
        "              \"GC\": [0, 255, 0],\n",
        "              \"CG\": [0, 128, 0],\n",
        "              \"UG\": [0, 0, 255],\n",
        "              \"GU\": [0, 0, 128],\n",
        "              \"UA\": [255, 0, 0],\n",
        "              \"AU\": [128, 0, 0]}\n",
        "    basepairs = [\"GC\", \"CG\", \"UG\", \"GU\", \"UA\", \"AU\"]\n",
        "\n",
        "    N = len(sequence)\n",
        "\n",
        "    matrix = np.full((N,N,3),255, dtype=\"uint8\")\n",
        "\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            pair = sequence[i] + sequence[j]\n",
        "            if i == j:\n",
        "                matrix[i, j, :] = colors[\"unpaired\"]\n",
        "            elif pair in basepairs:\n",
        "                matrix[i, j, :] = colors[pair]\n",
        "\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def make_matrix_from_basepairs(sequence: str, pairs: list) -> np.array:\n",
        "    \"\"\"\n",
        "    Takes a list of all the base pairs.\n",
        "    From the list a matrix is made, with each cell coresponding to a base pair colered black\n",
        "    \"\"\"\n",
        "    black = [0, 0, 0]\n",
        "\n",
        "    N = len(sequence)\n",
        "    matrix = np.full((N,N,3),255, dtype=\"uint8\")\n",
        "\n",
        "    for pair in pairs:\n",
        "        matrix[pair[0], pair[1], :] = black\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_matrix(matrix: np.array, name: str) -> None: \n",
        "    \"\"\"\n",
        "    Saves the matrix as a .png file \n",
        "    \"\"\"\n",
        "    plt.imsave(name, matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert sequences\n",
        "The sequences needs to be read from the .ct files and converted into images that can be used as input to the CNN.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def getCtFromTxt(txt_file):\n",
        "    \"\"\"\n",
        "    Takes a txt file containing the path to all the ct files and returns a list of the paths\n",
        "    \"\"\"\n",
        "    with open(txt_file, 'r') as f:\n",
        "        ct_files = f.readlines()\n",
        "    ct_files = [file.strip() for file in ct_files if file.strip()[0] != \"#\"]\n",
        "    return ct_files\n",
        "\n",
        "def save_to_matrices(file_list, input_matrix_path, output_matrix_path):\n",
        "    \"\"\"\n",
        "    For every file supplied in file_list:\n",
        "      a matrix of all possible base pairs is saved to input_matrix_path\n",
        "      a matrix showing the base pairs in the actual sequence is saved to output_matrix_path\n",
        "    \"\"\"\n",
        "    for file_name in file_list: \n",
        "        sequence, pairs = read_ct(file_name)\n",
        "        input_matrix = make_matrix_from_sequence(sequence)\n",
        "        save_matrix(input_matrix, os.path.join(input_matrix_path, os.path.splitext(os.path.basename(file_name))[0] + '.png'))\n",
        "        output_matrix = make_matrix_from_basepairs(sequence, pairs)\n",
        "        save_matrix(output, os.path.join(output_matrix_path, os.path.splitext(os.path.basename(file_name))[0] + '.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ct_files = getCtFromTxt(\"ct_files.txt\")\n",
        "\n",
        "file_list = []\n",
        "\n",
        "for file_name in ct_files: \n",
        "    if \"tRNA_database\" in file_name: \n",
        "        file_list.append(file_name)\n",
        "\n",
        "file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_matrix_path = \"input\"\n",
        "output_matrix_path = \"result\"\n",
        "\n",
        "# Create folders for images\n",
        "os.makedirs(input_matrix_path, exist_ok=True)\n",
        "os.makedirs(output_matrix_path, exist_ok=True)\n",
        "\n",
        "save_to_matrices(file_list, input_matrix_path, output_matrix_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up data for network\n",
        "\n",
        "### Splitting data into train and validation sets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def move_files(src_dir, dst_dir, file_list): \n",
        "    for filename in file_list: \n",
        "        src_path = os.path.join(src_dir, file_name)\n",
        "        dst_path = os.path.join(dst_dir, filename)\n",
        "        os.rename(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#Make directories\n",
        "directories = ['train', 'validation']\n",
        "subdirectories = ['input_images', 'output_images']\n",
        "\n",
        "for directory in directories: \n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    for subdirectory in subdirectories: \n",
        "        dir_path = os.path.join(directory, subdirectory)\n",
        "        os.makedirs(dir_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#List input and outputs\n",
        "input_images = os.listdir(input_matrix_path)\n",
        "output_images = os.listdir(output_matrix_path)\n",
        "\n",
        "#Make split\n",
        "input_train, input_valid, output_train, output_valid = train_test_split(input_images, output_images, train_size=0.8, random_state=42, shuffle=True) #NOTE - Change to the fraction we want nd whether we want shuffle or not\n",
        "\n",
        "\n",
        "#Move files to train and validation folders\n",
        "train_input_dir = 'train/input_images'\n",
        "train_output_dir = 'train/output_images'\n",
        "val_input_dir = 'validation/input_images'\n",
        "val_output_dir = 'validation/output_images'\n",
        "\n",
        "move_files(input_matrix_path, train_input_dir, input_train)\n",
        "move_files(output_matrix_path, train_output_dir, output_train)\n",
        "move_files(input_matrix_path, val_input_dir, input_valid)\n",
        "move_files(output_matrix_path, val_output_dir, output_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data and set up data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageToImageDataset(Dataset): \n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, input_dir, output_dir, transform = None): \n",
        "        self.input_dir = input_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.input_files = os.listdir(input_dir)\n",
        "        self.output_files = os.listdir(output_dir)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self): \n",
        "        return len(self.input_files)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        input_image =  plt.imread(os.path.join(self.input_dir, self.input_files[idx]))\n",
        "        output_image = plt.imread(os.path.join(self.output_dir, self.output_files[idx]))\n",
        "\n",
        "        if self.transform: \n",
        "            input_image = self.transform(input_image)\n",
        "            output_image = self.transform(output_image)\n",
        "        \n",
        "        return input_image, output_image\n",
        "\n",
        "\n",
        "mean = [] #NOTE - Find these for normalization\n",
        "std = []\n",
        "\n",
        "dataTransformer = transforms.Compose([\n",
        "    transforms.ToTensor(), #Convert image to tensor\n",
        "    transforms.Normalize(mean=mean, std=std) \n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = ImageToImageDataset(train_input_dir, train_output_dir, dataTransformer)\n",
        "validation_dataset = ImageToImageDataset(val_input_dir, val_output_dir, dataTransformer)\n",
        "\n",
        "batch_size = '?' #NOTE - Change!\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #Do shuffle need to be true???\n",
        "val_loader = DataLoader(validation_dataset, batch_size=batch_size)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
